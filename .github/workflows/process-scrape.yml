name: Process Instagram Scrape

on:
  workflow_dispatch:
    inputs:
      dataset_url:
        description: 'Apify Dataset URL (e.g., https://api.apify.com/v2/datasets/ABC123/items?format=json)'
        required: true
        type: string
      resume:
        description: 'Resume from previous run checkpoint (true/false)'
        required: false
        default: 'true'
        type: string

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  DATA_INGEST_TOKEN: ${{ secrets.DATA_INGEST_TOKEN }}
  GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}

jobs:
  process-scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # 3 hours max

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: scripts/package-lock.json

      - name: Install dependencies
        working-directory: scripts
        run: npm ci

      # Download previous progress if resuming
      - name: Download previous progress
        if: ${{ github.event.inputs.resume == 'true' }}
        uses: dawidd6/action-download-artifact@v3
        with:
          name: scrape-progress-latest
          path: scripts/results/
          if_no_artifact_found: warn
          search_artifacts: true
        continue-on-error: true

      - name: Show resume status
        working-directory: scripts
        run: |
          if [ -f results/progress.json ]; then
            echo "üìÇ Found checkpoint file:"
            cat results/progress.json | head -20
          else
            echo "üìã Starting fresh - no checkpoint found"
          fi

      - name: Process scrape
        working-directory: scripts
        run: |
          echo "üöÄ Starting scrape processing..."
          node process-scrape.js "${{ github.event.inputs.dataset_url }}"
          exit_code=$?
          
          # Check if we exited due to timeout (clean exit = 0)
          if [ $exit_code -eq 0 ] && [ -f results/progress.json ]; then
            echo "‚è∞ Processing paused for timeout - resume by re-running workflow"
          fi
          
          exit $exit_code

      # Always upload progress for potential resume
      - name: Upload progress for resume
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-progress-latest
          path: scripts/results/progress.json
          retention-days: 7
          if-no-files-found: ignore
          overwrite: true

      - name: Upload final results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-results-${{ github.run_id }}
          path: scripts/results/
          retention-days: 30
